import os
import re
import subprocess

from error import Error
from pathlib import Path
from collections import defaultdict
from contextlib import contextmanager


@contextmanager
def cd(path: Path):
    """Sets the cwd within the context
    Args:
        path (Path): The path to the cwd
    Yields:
        None
    """
    origin = Path().absolute()
    try:
        os.chdir(path)
        yield
    finally:
        os.chdir(origin)

def tag(content: str, tag_name: str) -> str:
    '''

    Args:
        content:
        tag_name:

    Returns:
        if content = NULL  =>   NULL
        if content != NULL =>   <tag_name>
                                content
                                </tag_name>
     '''
    if not content:
        return content
    return f"\n<{tag_name}>\n{content}\n</{tag_name}>\n"

def compile_and_record_query(
        code: str,
        work_dir: str,
        prompt: str = "",
        log_id: str = "default",
) -> subprocess.CompletedProcess:
    '''
    Compile Rsut code and output errors
    Args:
        Code: Rust code block
        work_dir:  Workplace # work-dir/wspace/
        prompt:  Tips
        log_id:  Log identifier
    Returns:
        comp_output:  Compile output information
    '''
    if Path(f"{work_dir}").is_dir():
        with cd(f"{work_dir}"):
            subprocess.run(f"cargo clean", capture_output=True, shell=True)
    else:
        subprocess.run(f"cargo new --lib {work_dir}", capture_output=True, shell=True) # Run external command: Clean up files generated by the project
        os.makedirs(f"{work_dir}/logs", exist_ok=True)
        # Add Dependency
        with open(f"{work_dir}/Cargo.toml", "a") as fw:  # add some dependencies by default
            fw.write('rand = "0.8.4"\n')
            fw.write('libc = "0.2"\n')
            fw.write('regex = "1.10.2"\n')  # c urlparser benchmark
            fw.write('lazy_static = "1.4.0"\n')  # go ACH benchmark
            fw.write('once_cell = "1.19.0"\n')  # go ACH benchmark

    os.makedirs(f"{work_dir}/logs", exist_ok=True)
    with open(f"{work_dir}/logs/{log_id}_prompt.txt", "w") as f:
        f.write(f"{prompt}")
    with open(f"{work_dir}/logs/{log_id}_code.rs", "w") as f:
        f.write(code)  # for logging purpose
    # 添加源码
    with open(f"{work_dir}/src/lib.rs", "w") as f:
        f.write(code)  # has to be written in main, this will be over-written with fixes
    # Compile project (requires network support)
    with cd(f"{work_dir}"):
        comp_output = subprocess.run(
            f'RUSTFLAGS="-Z track-diagnostics -Z time-passes" cargo build --manifest-path Cargo.toml',
            capture_output=True,
            shell=True,
        )

    with open(f"{work_dir}/logs/{log_id}_err.txt", "wb") as file:
        file.write(comp_output.stderr)

    return comp_output

def parse_error_timepass(stderr, fname):
    '''
    Analyzing error messages and compilation steps during Rust compilation process
    Args:
        stderr： Contains the standard error stream output during the compilation process, passed in the form of a byte stream.
        fname： The file name is used to identify and handle specific compilation projects within the function (assuming it is the cargo project name).
    Returns:
        errors:  A list containing all compilation errors.
        err_code_num:  Dictionary, record the number of occurrences of each error code.
        err_diag_num:  Dictionary, record the frequency of each error diagnosis.
        compilation_steps:  A list containing compilation steps.
        len(errors):  The total number of errors.
    '''
    lines = stderr.decode("utf-8").splitlines()
    ln_cnt = 0
    line = lines[ln_cnt]
    # wspace is the project name, and if the project name changes, it must also be changed here
    while (f"Compiling wspace" not in line):  # WATCHOUT HERE: wspace is the name of the cargo project. Has to be updated if the path that we write transpiled rust code changes
        ln_cnt += 1
        line = lines[ln_cnt]

    relevant_lines = lines[ln_cnt + 1 :]

    errors, compilation_steps = [], [] # Store error blocks (Error class) and some operations outside of common_comps_steps during compilation
    cur_err_body, err_block = "", False
    common_comp_steps = ["free_global_ctxt", "total"]
    for line in relevant_lines:
        if re.match(r"error: could not compile \`wspace\` \(lib\) due to \d+ previous errors?",line):
            break
        if line.startswith("time:"):
            if err_block:
                errors.append(Error(cur_err_body))
                cur_err_body = ""
                err_block = False
            comp_step = re.split(r"\s+", line)[-1]  # line.split(r"\s+")[-1]
            if comp_step not in common_comp_steps:
                compilation_steps.append(comp_step)
        elif re.match(r"error(\[E\d\d\d\d\])?:", line) is not None:
            if err_block:
                errors.append(Error(cur_err_body))
            cur_err_body = line + "\n"
            err_block = True
        elif err_block:
            cur_err_body = cur_err_body + line + "\n"
        else:
            pass

    err_code_num, err_diag_num = defaultdict(int), defaultdict(int)
    for err in errors:
        err_code_num[err.code] += 1
        err_diag_num[err.diagnostic] += 1

    return errors, err_code_num, err_diag_num, compilation_steps, len(errors)

def parse_error_coarse(stderr):
    '''
    Analyze rough error messages during Rust compilation process
    Args:
        stderr:  error message
    Returns:
        errors:  List of parsed error objects.
        err_c_num_dict:  The number of occurrences of each type of error.
        err_comp_phase_num_dict:  The number of times errors occur during each compilation stage
    '''
    msg_blocks = stderr.decode("utf-8").split("\n\n")
    # err_blocks, err_codes = [], []
    errors = []
    err_c_num_dict = defaultdict(int)
    err_comp_phase_num_dict = defaultdict(int)
    for body in msg_blocks[:-1]:
        # Filtering and matching criteria
        if (
            "Finished" not in body
            and "warning:" not in body
            and len(body.split("\n")) > 3
        ):  # TODO make this check more proper/robust, this is for Cargo build
            err_c_match = re.search(r"error\[E[0-9]+\]", body)
            # err_nc_match = re.search(r"error: ", body)
            diag_match = re.search(r"-Ztrack-diagnostics.*", body)

            # elif err_nc_match is not None and len(body.split("\n")) > 2:  # second part is needed because of error summary at the end of the file
            if err_c_match is not None:
                err_c = err_c_match.group(0)
            else:
                err_c = "E[NOCODE]"

            # precaution against some strange reason
            if diag_match is not None:
                compile_step = diag_match.group(0).split("/")[1]
            else:
                compile_step = "NotFound"

            body = re.sub(
                r"\s*(Compiling|Updating).*\n", "", body
            )  # the first block contains other logs, clean them

            err = Error(body)
            errors.append(err)

            err_c_num_dict[err_c] += 1
            err_comp_phase_num_dict[compile_step] += 1

    return errors, err_c_num_dict, err_comp_phase_num_dict
